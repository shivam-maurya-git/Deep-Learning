{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45f54460-1d83-488d-ab19-09fbf11a5383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fbd09b4e-d43a-4100-a2b7-681b9b978ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = [[2,3,4,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7c16539-7cd0-4294-bcd9-462a005a3099",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.tensor(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa8e7815-104e-4bb8-9935-dee74fabba38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3, 4, 5]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e071a1dd-986e-4da8-bb45-8c867e8d550f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6fd9c2b4-0928-4bba-a8f0-9a909562f591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66192eab-2925-475c-a5c9-8f521b058e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiva\\AppData\\Local\\Temp\\ipykernel_9268\\1296307948.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t,dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor(t,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14d09d54-70b1-479a-ab01-704113ee8d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_ly  = nn.Linear(in_features=4,out_features=2,bias = True,dtype= torch.float32) \n",
    "#default dtype for nn.Linear is torch.float32\n",
    "#usually float32, but your input is Long (int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e3cfecba-40c8-44e7-811d-43be07c26c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4, out_features=2, bias=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_ly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "711113c8-56fc-418b-8997-ac69e8c310af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0223, 0.0398]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_ly(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fb1bf88a-2ac1-4149-b99e-9f6fde8a6445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.0166, -0.1384], requires_grad=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_ly.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "59fda8c6-9e7b-4dff-b673-610559bc9e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0065, -0.2728,  0.4926, -0.0318],\n",
       "        [-0.3674,  0.1519,  0.3445, -0.1841]], requires_grad=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_ly.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "15947b1e-7348-48b0-9015-07eb17448f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ly_3 = nn.Sequential(\n",
    "    nn.Linear(4,2),\n",
    "    nn.Linear(2,5),\n",
    "    nn.Linear(5,7)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7337bf58-a0b1-481d-8389-b9c7c26348c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=2, bias=True)\n",
       "  (1): Linear(in_features=2, out_features=5, bias=True)\n",
       "  (2): Linear(in_features=5, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ly_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1de27c79-a913-4d91-8ebe-d33296cacab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1369,  0.2524, -0.3470,  0.6467,  0.4119, -0.1783,  0.4052]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ly_3(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "10bd13d1-656e-4a6a-93c0-57e00313a5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3226, -0.1360,  0.3030, -0.0428],\n",
      "        [ 0.4500, -0.1592,  0.1149,  0.0598]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1688, 0.3218], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1029,  0.1337],\n",
      "        [-0.1956, -0.1821],\n",
      "        [-0.0337, -0.3637],\n",
      "        [-0.6209, -0.3425],\n",
      "        [ 0.6786, -0.6741]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.6527, -0.3591, -0.1481,  0.5721, -0.3074], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0321, -0.0765,  0.4268, -0.1182,  0.1424],\n",
      "        [-0.3665, -0.0072,  0.2238, -0.1812,  0.2332],\n",
      "        [ 0.1664, -0.1111,  0.2714,  0.0674,  0.0866],\n",
      "        [ 0.2637, -0.1408, -0.3696, -0.4422,  0.1794],\n",
      "        [ 0.0160, -0.3679, -0.1445, -0.2565, -0.2926],\n",
      "        [ 0.3538,  0.0876, -0.2574, -0.1536,  0.2868],\n",
      "        [-0.2286, -0.2146,  0.2744,  0.0892, -0.2017]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.3305,  0.2376, -0.1086,  0.0315, -0.3408, -0.2007,  0.3424],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in ly_3.parameters():\n",
    "    # k = i.numel()\n",
    "    # print(k)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0c638937-ca62-4359-944c-580df8d93630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3., 4., 5.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "00fa5ce6-73d5-40b5-835e-fab2711cebe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b2e38291-196a-461e-8958-155448793796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8808, 0.9526, 0.9820, 0.9933]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1fade123-4b73-410f-82b3-f0abc27335ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "soft = nn.Softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7fa5ac19-dd21-4fe5-887f-a54e26560b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0321, 0.0871, 0.2369, 0.6439]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
